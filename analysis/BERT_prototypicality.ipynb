{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b396f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ec5475a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x25e0b60f2e0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# init model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "model.eval()\n",
    "# init softmax to get probabilities later on\n",
    "sm = torch.nn.Softmax(dim=0)\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d312d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(sentence, nouns):\n",
    "    \n",
    "    token_ids = tokenizer.encode(sentence, return_tensors='pt')\n",
    "    masked_position = (token_ids.squeeze() == tokenizer.mask_token_id).nonzero().item()\n",
    "\n",
    "    # forward\n",
    "    output = model(token_ids)\n",
    "    last_hidden_state = output[0].squeeze(0)\n",
    "    # only get output for masked token\n",
    "    # output is the size of the vocabulary\n",
    "    mask_hidden_state = last_hidden_state[masked_position]\n",
    "    # convert to probabilities (softmax)\n",
    "    # giving a probability for each item in the vocabulary\n",
    "    probs = sm(mask_hidden_state)\n",
    "    \n",
    "    return([probs[tokenizer.convert_tokens_to_ids(noun)].item() for noun in nouns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "632d3d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_file = open(\"nounlist.txt\", \"r\")\n",
    "nouns = text_file.read().splitlines() \n",
    "\n",
    "a_sentence = f\"A {tokenizer.mask_token} is an animal\"\n",
    "an_sentence = f\"An {tokenizer.mask_token} is an animal\"\n",
    "\n",
    "token_is_a_animal_probs = get_probs(a_sentence,nouns)\n",
    "token_is_an_animal_probs = get_probs(an_sentence,nouns)\n",
    "\n",
    "animal_probs = [max(token_is_an_animal_probs[i],token_is_a_animal_probs[i]) for i,x in enumerate(token_is_an_animal_probs)]\n",
    "\n",
    "animal_df = pd.DataFrame({'nouns':nouns, 'animal':animal_probs}).sort_values(by=['animal'],ascending=False)\n",
    "animal_df.loc[animal_df['nouns']=='cat']\n",
    "animal_df.to_csv('animal_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1371192",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_fruit_sentence = f\"A {tokenizer.mask_token} is a fruit\"\n",
    "an_fruit_sentence = f\"An {tokenizer.mask_token} is a fruit\"\n",
    "\n",
    "token_is_a_fruit_probs = get_probs(a_fruit_sentence,nouns)\n",
    "token_is_an_fruit_probs = get_probs(an_fruit_sentence,nouns)\n",
    "\n",
    "fruit_probs = [max(token_is_an_fruit_probs[i],token_is_an_fruit_probs[i]) for i,x in enumerate(token_is_an_fruit_probs)]\n",
    "\n",
    "fruit_df = pd.DataFrame({'nouns':nouns, 'fruit':fruit_probs}).sort_values(by=['fruit'],ascending=False)\n",
    "fruit_df.to_csv('fruit_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3eb9f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = ['dog','spider']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa874284",
   "metadata": {},
   "outputs": [],
   "source": [
    "animal_probs = [tokenizer.convert_tokens_to_ids(noun) for noun in nouns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4af26bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3899, 6804]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animal_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "09575e46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.5253e-06)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs[pudding_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baab372a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
